[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Data Science for Political Science",
    "section": "",
    "text": "This document will include important links and course notes for 01:790:391:01: Data Science for Political Science for the fall 2022 semester.\n\nThis site will be updated throughout the semester with new content.\nThe Canvas modules will provide links to the relevant sections to review for a given week of the course.\nThe primary text for the course is Quantitative Social Science: An Introduction by Kosuke Imai. We will refer to this as QSS in the notes.\nThis is a new and living document. If you spot errors or have questions or suggestions, please email me at k.mccabe@rutgers.edu or post to the course Canvas site.\nOccasionally the notes are updated with embedded video explainers of the code in different sections."
  },
  {
    "objectID": "intro.html",
    "href": "intro.html",
    "title": "1  Introduction",
    "section": "",
    "text": "First: What is Data Science?\n\nData Science involves a combination of math/statistics and programming/coding skills, which, for our purposes, we will combine with social science knowledge.\n\nDrew Conway has a nice venn diagram of how these different skill sets intersect.\nNote: This course will not assume prior familiarity with data science in general or coding, specifically. For those brand new to data science, the idea of learning to code may seem intimidating, but anyone can succeed with a bit of patience and an open mind.\n\n\n\nNext: What is political science?\n\nThe science of politics, of course! Politics focuses on studying governance and the distribution of power in society, broadly conceived.\n\nHow else might you define politics and political science? What do we study in political science?\n\n\n\n\nExample: Mapping poverty using mobile phone and satellite data\nResearchers used modern data sources, including mobile phone data, as a way to predict and describe poverty in different geographic regions. These tools helped social scientists come up with methods that are much more cost-effective and efficient, but still as accurate as traditional methods for this type of measurement.\n\nHow might measures of global poverty be useful to political scientists?\n\n\nSocial Science Goals\nWe have several goals in social science. Here are four that data science can help us pursue:\n\nDescribe and measure\n\nHas the U.S. population increased?\n\nExplain, evaluate, and recommend (study of causation)\n\nDoes expanding Medicaid improve health outcomes?\n\nPredict\n\nWho will win the next election?\n\nDiscover\n\nHow do policies diffuse across states?\n\n\nWhat are other examples of these goals?\nNote: In this course, we are exploiting the benefits of quantitative data to help achieve goals of social science. However, quantitative data have their shortcomings, too. We will also discuss the limitations of various applications of social science data, and we encourage you to always think critically about how we are using data.\n\n\n\nThis course will provide you with a taste of each of these social science goals, and how the use of data can help achieve these goals. By the end of the course, you should be able to\n\nProvide examples of how quantitative data may be used to help answer social science research questions.\nCompare and contrast the goals of description, causation, prediction, and discovery in social science research.\nUse the programming language R to import and explore social science data and conduct basic statistical analyses.\nInterpret and describe visual displays of social science data, such as graphs and maps.\nDevelop your own analyses and visualizations to understand social science phenomena.\n\nIf you are someone that loves data, we hope you will find this course engaging. If you are someone who loathes or finds the idea of working with data and statistics alarming, we hope you keep an open mind. We will meet you where you are. This course will not assume knowledge of statistical software, and there will be plenty of opportunities to ask questions and seek help from classmates and the instructor throughout the semester.\nThe first section of course will walk people through how to use the statistical program– R– that we will employ this semester.\nWill this course help me in the future?\nEven if you do not plan on becoming a social scientist or a data scientist, an introduction to these skills may prove helpful throughout your academic and professional careers.\n\nTo become an informed consumer of news articles and research involving quantitative analyses.\nTo practice analytical thinking to make informed arguments and decisions.\nTo expand your toolkit for getting a job that may involve consuming or performing some data analysis, even if that is not the traditional role.\n\nExample: Journalism- How 5 Data Dynamos Do Their Jobs"
  },
  {
    "objectID": "intro.html#rsetup",
    "href": "intro.html#rsetup",
    "title": "1  Introduction",
    "section": "1.2 Setup in R",
    "text": "1.2 Setup in R\nGoal\nBy the end of the first week of the course, you will want to have R and RStudio installed on your computer (both free) and feel comfortable using R as a calculator.\nR is an application that processes the R programming language in a statistical computing environment. RStudio is also an application, which serves as a user interface that makes working in R easier. We will primarily open and use RStudio to work with R.\nIn other classes, you may come across Stata, SPSS, Excel, or SAS, which are programs that also conduct data analysis. R has the advantage of being free and open-source. Even after you leave the university setting, you will be able to use R/RStudio for free. As an open-source program, it is very flexible, and a community of active R/RStudio users is constantly adding to and improving the program.\nR and RStudio Installation\nThis content follows and reinforces QSS 1.3. Additional resources are also linked below.\n\nThis video from Professor Christopher Bail explains why many social scientists use R and describes the R and RStudio installation process. This involves\n\nGoing to cran, select the link that matches your operating system, and then follow the installation instructions, and\nVisiting RStudio and follow the download and installation instructions. R is the statistical software and programming language used for analysis. RStudio provides a convenient user interface for running R code."
  },
  {
    "objectID": "intro.html#first-time-working-in-r-and-rstudio",
    "href": "intro.html#first-time-working-in-r-and-rstudio",
    "title": "1  Introduction",
    "section": "1.3 First Time Working in R and RStudio",
    "text": "1.3 First Time Working in R and RStudio\nThis next section provides a few notes on using R and RStudio now that you have installed it. In this section, we cover the following materials:\n\nUsing R as a calculator and assigning objects using <-\nSetting your working directory and the setwd() function.\nCreating and saving an R script\n\nThis section highlights important concepts from QSS chapter 1.\n\n1.3.1 Open RStudio\nRStudio is an open-source and free program that greatly facilitates the use of R, especially for users new to programming. Once you have downloaded and installed R and RStudio, to work in R, all you need to do now is open RStudio (it will open R). It should look like this, though your version numbers will be different:\n\nNote: The first time you open RStudio, you likely only have the three windows above. We will want to create a fourth window by opening an R script to create the fourth window.\n\nTo do this, in RStudio, click on File -> New -> R script in your computer’s toolbar. This will open a blank document for text editing in the upper left of the RStudio window. We will return to this window in a moment.\n\nYou can alternatively click on the green + sign indicator in the top-left corner of the RStudio window, which should give you the option to create a new R script document.\n\n\nNow you should have something that looks like this, similar to Figure 1.1. in QSS:\nNote: The first time you open RStudio, you likely only have the three windows above. We will want to create a fourth window by opening an R script to create the fourth window.\n\nTo do this, in RStudio, click on File -> New -> R script in your computer’s toolbar. This will open a blank document for text editing in the upper left of the RStudio window. We will return to this window in a moment.\n\nYou can alternatively click on the green + sign indicator in the top-left corner of the RStudio window, which should give you the option to create a new R script document.\n\n\nNow you should have something that looks like this, similar to Figure 1.1. in QSS:\n\n\nThe upper-left window has our script document that will contain code.\nThe lower-left window is the console. This will show the output of the code we run. We will also be able to type directly in the console.\nThe upper-right window shows the environment (and other tabs, such as the history of commands). When we load and store data in RStudio, we will see a summary of that in the environment.\nThe lower-right window will enable us to view plots and search help files, among other things.\n\n\n\n1.3.2 Using R as a Calculator\nThe bottom left window in your RStudio is the Console. You can type in this window to use R as a calculator or to try out commands. It will show the raw output of any commands you type. For example, we can try to use R as a calculator. Type the following in the Console (the bottom left window) and hit “enter” or “return” on your keyboard:\n\n5 + 3\n\n[1] 8\n\n5 - 3\n\n[1] 2\n\n5^2\n\n[1] 25\n\n5 * 3\n\n[1] 15\n\n5/3\n\n[1] 1.666667\n\n(5 + 3) * 2\n\n[1] 16\n\n\nIn the other RStudio windows, the upper right will show a history of commands that you have sent from the text editor to the R console, along with other items. The lower right will show graphs, help documents and other features. These will be useful later in the course.\n\n\n1.3.3 Working in an R Script\nEarlier, I asked you to open an R script in the upper left window by doing File, then New File, then R Script. Let’s go back to working in that window.\nSet your working directory setwd()\n(Almost) every time you work in RStudio, the first thing you will do is set your working directory. This is a designated folder in your computer where you will save your R scripts and datasets.\nThere are many ways to do this.\n\nAn easy way is to go to Session -> Set Working Directory -> Choose Directory. I suggest choosing a folder in your computer that you can easily find and that you will routinely use for this class. Go ahead and create/select it.\nNote: when you selected your directory, code came out in the bottom left Console window. This is the setwd() command which can also be used directly to set your working directory in the future.\nIf you aren’t sure where your directory has been set, you can also type getwd() in your Console. Try it now\n\n\n## Example of where my directory was\ngetwd()\n\nIf I want to change the working directory, I can go to the top toolbar of my computer and use Session -> Set Working Directory -> Choose Directory or just type my file pathway using the setwd() below:\n\n## Example of setting the working directory using setwd().\n## Your computer will have your own file path.\nsetwd(\"/Users/ktmccabe/Dropbox/Rutgers Teaching/\")\n\nSaving the R Script\nLet’s now save our R script to our working directory and give it an informative name. To do so, go to File, then Save As, make sure you are in the same folder on your computer as the folder you chose for your working directory.\nGive the file an informative name, such as: “McCabeWeek1.R”. Note: all of your R scripts will have the .R extension.\n\n\n1.3.4 Preparing your R script\nNow that we have saved our R script, let’s work inside of it. Remember, we are in the top-left RStudio window now.\n\nJust like the beginning of a paper, you will want to title your R script. In R, any line that you start with a # will not be treated as a programming command. You can use this to your advantage to write titles/comments. Below is a screenshot example of a template R script.\nYou can specify your working directory at the top, too. Add your own filepath inside setwd()\n\n\n\nThen you can start answering problems in the rest of the script.\nThink of the R script as where you write the final draft of your paper. In the Console (the bottom-left window), you can mess around and try different things, like you might when you are taking notes or outlining an essay. Then, write the final programming steps that lead you to your answer in the R script. For example, if I wanted to add 5 + 3, I might try different ways of typing it in the Console, and then when I found out 5 + 3 is the right approach, I would type that into my script.\n\n\n\n1.3.5 Executing Commands in your R script\nThe last thing we will note in this initial handout is how to execute commands in your R script.\nTo run / execute a command in your R script (the upper left window), you can\n\nHighlight the code you want to run, and then hold down “command + return” on a Mac or “control + enter” on Windows\nPlace your cursor at the end of the line of code (far right), and hit “command + return” on a Mac or “control + return” on Windows, or\nDo 1 or 2, but instead of using the keyboard to execute the commands, click “Run” in the top right corner of the upper-left window.\n\nTry it: Type 5 + 3 in the R script. Then, try to execute 5 + 3. It should look something like this:\n\nAfter you executed the code, you should see it pop out in your Console:\n\n5 + 3\n\n[1] 8\n\n\n\nNote: The symbol # also allows for annotation behind commands or on a separate line. Everything that follows # will be ignored by R. You can annotate your own code so that you and others can understand what each part of the code is designed to do.\n\n## Example\nsum53 <- 5 + 3 # example of assigning an addition calculation\n\n\n\n1.3.6 Objects\nSometimes we will want to store our calculations as “objects” in R. We use <- to assign objects by placing it to the left of what we want to store. For example, let’s store the calculation 5 + 3 as an object named sum53:\n\nsum53 <- 5 + 3\n\nAfter we execute this code, sum53 now stores the calculation. This means, that if we execute a line of code that just hassum53`, it will output 8. Try it:\n\nsum53\n\n[1] 8\n\n\nNow we no longer have to type 5 + 3, we can just type sum53. For example, let’s say we wanted to subtract 2 from this calculation. We could do:\n\nsum53 - 2\n\n[1] 6\n\n\nLet’s say we wanted to divide two stored calculations:\n\nten <- 5 + 5\ntwo <- 1 + 1\nten / two\n\n[1] 5\n\n\nThe information stored does not have to be numeric. For example, it can be a word, or what we would call a character string, in which case you need to use quotation marks.\n\nmccabe <- \"professor for this course\"\nmccabe\n\n[1] \"professor for this course\"\n\n\nNote: Object names cannot begin with numbers and no spacing is allowed. Avoid using special characters such as % and $, which have specific meanings in R. Finally, use concise and intuitive object names.\n\nGOOD CODE: practice.calc <- 5 + 3\nBAD CODE: meaningless.and.unnecessarily.long.name <- 5 + 3\n\nWhile these are simple examples, we will use objects all the time for more complicated things to store (e.g., like full datasets!) throughout the course.\nWe can also store an array or “vector” of information using c()\n\nsomenumbers <- c(3, 6, 8, 9)\nsomenumbers\n\n[1] 3 6 8 9\n\n\nImportance of Clean Code\nIdeally, when you are done with your R script, you should be able to highlight the entire script and execute it without generating any error messages. This means your code is clean. Code with typos in it may generate a red error message in the Console upon execution. This can happen when there are typos or commands are misused.\nFor example, R is case sensitive. Let’s say we assigned our object like before:\n\nsum53 <- 5 + 3\n\nHowever, when we went to execute sum53, we accidentally typed Sum53:\n\nSum53\n\nError in eval(expr, envir, enclos): object 'Sum53' not found\n\n\nOnly certain types of objects can be used in mathematical calculations. Let’s say we tried to divide mccabe by 2:\n\nmccabe / 2\n\nError in mccabe/2: non-numeric argument to binary operator\n\n\nA big part of learning to use R will be learning how to troubleshoot and detect typos in your code that generate error messages."
  },
  {
    "objectID": "intro.html#assignment-1",
    "href": "intro.html#assignment-1",
    "title": "1  Introduction",
    "section": "1.4 Assignment 1",
    "text": "1.4 Assignment 1\nBelow is an exercise that will demonstrate you are able to use R as a calculator and create R scripts, as well as locate important course platforms.\nWe will walk through this assignment together during class, but you are welcome to try to do this ahead of time on your own. You will submit, on Canvas, two documents prior to the deadline.\n\nAn R script (.R) file with your code. Follow the best practices by titling your script and using # comments to explain your steps. This code should be clean. I should be able to run your code to verify that the code produces the answers you write down.\nA Word document / Google Docs document or pdf with answers to the written questions (Problems 3-6 below). This document should also have a title with your name on it.\n\nYou may also alternatively submit a compiled RMarkdown document. We will discuss what RMarkdown is during class.\n\n\nAssignment Exercises\n\nCreate an R script saved as ``LastnameSetup1.R” (use your last name). Within the R script, follow the example from this handout and title the script.\nSet your working directory, and include the file pathway (within setwd()) at the top of your .R script.\nDo the calculation 8 + 3 - 2 in R. Store it as an object with an informative name. Report the answer.\nDo the calculation 5 x 3 in R. Store it as an object with an informative name. Report the answer.\nAdd these two calculations together. Note: do this by adding together the objects you created, not the underlying raw calculations. Report the answer.\nWrite down how you will complete your R assignments this semester. For example, if you have a personal laptop with R and RStudio on it, you will simply write “I will use my personal laptop.” If you don’t have a personal computer or laptop, please indicate where on campus or off-campus you will have regular access to a computer with R/RStudio to do your work. It is essential that you have regular access to a computer so that you will not fall behind in this course.\nNavigate to the course Piazza site and post a message. This can be as simple as “hello” or a reply to another person’s post. (No need to report this in your submission.)"
  },
  {
    "objectID": "intro.html#r-markdown",
    "href": "intro.html#r-markdown",
    "title": "1  Introduction",
    "section": "1.5 R Markdown",
    "text": "1.5 R Markdown\nAn R Markdown document, which you can create in RStudio, allows you to weave together regular text, R code, and the output of R code in the same document. This can be very convenient when conducting data analysis because it allows you more space to explain what you are doing in each step. It can also be an effective platform for writing a report on a data analysis, similar to what you do when you write up a problem set.\nNote: RMarkdown is not required for this course. It is up to you if you would like to write your problem sets in RMarkdown\nR Markdown documents can be “compiled” into html, pdf, or docx documents. Below is an example of what a compiled html file looks like.\n\nNote that the image has both written text and a gray chunk, within which there is some R code, as well as the output of the R code (e.g., the number 8 and the image of the histogram plot)\n\n\n\n\nWe say this is a “compiled” RMarkdown document because it differs from the raw version of the file, which is a .Rmd file format. Below is an example of what the raw .Rmd version looks like, compared to the compiled html version."
  },
  {
    "objectID": "02-Description.html",
    "href": "02-Description.html",
    "title": "2  Description",
    "section": "",
    "text": "What are things we want to describe in political science?\nWhat else? What does description help us achieve?\nGenerate ideas for other goals, such as explanation and prediction"
  },
  {
    "objectID": "02-Description.html#process-of-describing",
    "href": "02-Description.html#process-of-describing",
    "title": "2  Description",
    "section": "2.1 Process of Describing",
    "text": "2.1 Process of Describing\nHow do we go about a descriptive quantitative analysis?\n\nSubstantive Expertise: Start with a topic, puzzle, or question (e.g., How is the economy doing?)\nFind outcome data relevant to that question (e.g., GDP)\n\nStart from a concept: what we want to describe (i.e., health of the economy)\nMove toward an “operationalization” (i.e., a way to measure it)\nEasy! except… social science is messy. Our concepts are rich, while our measures may be very narrow or concrete.\n\nFor example, GDP is one way to measure economic health, but is it the only measure?\nChoose measures based on validity, reliability, cost\n\n\nFind multiple relevant units or “data points”\n\nE.g., Multiple years of data (e.g., U.S., from 1900 to 2020)\nE.g., Multiple countries from one year (e.g., U.S. to Germany to other countries)\n\nSummarize the data to help answer the question\n\n\n2.1.1 Example Process\n\nHow is the economy doing?\nFind outcome data relevant to that question\n\nLet’s ask people\n\nFind multiple relevant units or data points\n\nWe will ask several people. Each person will be a data point.\n\nSummarize the data\n\nLet’s take the mean\n\n\n\nHow would you summarize information in explaining it to another person? You would probably want to describe how most people feel about the economy. In other words, you would describe the “central tendency” of people’s responses (the central tendency of the data)."
  },
  {
    "objectID": "02-Description.html#summarizing-univariate-data",
    "href": "02-Description.html#summarizing-univariate-data",
    "title": "2  Description",
    "section": "2.2 Summarizing univariate data",
    "text": "2.2 Summarizing univariate data\nFor a video explainer of the code in this section, see below. The video only discusses the code. Use the notes and lecture discussion for additional context. (Via youtube, you can speed up the playback to 1.5 or 2x speed.)\n\n\n\n\n\n\n\n\n\nUnivariate data refers to data coming from one “variable,” where a variable captures the values of a changing characteristic.\nOur set of values is Outcome = {0,0,0,0,1,1,0,1,0,1}.\n\nWe will call this a vector of values, where a vector is just a collection of things.\nBecause our vector contains only numbers, we will call it a numeric vector.\nEach value can be indexed by i, denoting the position of the value in the\nFor example, Jesse is in position i=10 of the vector, and his value is 1\n\nWe can create vectors in R by using c() and assigning <- it to an object we will call Outcome.\n\nOutcome <- c(0,0,0,0,1,1,0,1,0,1) # Use commas to separate values\n\nWe can extract a particular value within our vector using brackets\n\nOutcome[10]\n\n[1] 1\n\n\nWe can label our outcomes using names()\n\nnames(Outcome) <-c(\"Joe\",\"Sally\", \"Trevor\", \"Emily\", \"Mark\",\n                   \"Sarah Jane\", \"Stacey\", \"Steve\", \"Phoebe\", \"Jesse\")\nOutcome[10]\n\nJesse \n    1 \n\n\nWe can overwrite whole vectors or values within a vector\n\nOutcome <- c(5,0,2, 6,1,1, 7, 8, 0, 1) # oops we put the wrong numbers\nOutcome\n\n [1] 5 0 2 6 1 1 7 8 0 1\n\nOutcome <- c(0,0,0,0,1,1,0,1,0,1) # no problem, just overwrite it\nOutcome\n\n [1] 0 0 0 0 1 1 0 1 0 1\n\n\nOops we accidentally type a 0 for Jesse.\n\nOutcome <- c(0,0,0,0,1,1,0,1,0,0) # oops typo for Jesse\nOutcome\n\n [1] 0 0 0 0 1 1 0 1 0 0\n\nOutcome[10] <- 1 # no prob bob. Assign a 1 in position 10\nOutcome\n\n [1] 0 0 0 0 1 1 0 1 0 1\n\n\nVectors do not have to be numeric. Character vectors contain a collection of words and phrases. In R, we use quotations around character values\nExample: let’s create a vector of names that we will call People.\n\nPeople <- c(\"Joe\",\"Sally\", \"Trevor\", \"Emily\", \"Mark\", \"Sarah Jane\", \"Stacey\", \"Steve\", \"Phoebe\", \"Jesse\")\nPeople[10]\n\n[1] \"Jesse\"\n\n\nWe can use the R function class() to tell us the type of object we have.\n\nclass(Outcome)\n\n[1] \"numeric\"\n\nclass(People)\n\n[1] \"character\""
  },
  {
    "objectID": "02-Description.html#functions-to-summarize-univariate-data",
    "href": "02-Description.html#functions-to-summarize-univariate-data",
    "title": "2  Description",
    "section": "2.3 Functions to summarize univariate data",
    "text": "2.3 Functions to summarize univariate data\nFor univariate data, often we are interested in describing the range of the values and their central tendency.\n\nrange: the minimum (min()) and maximum (max()) values\nmean: the average value (mean())\n\nThe average is the sum of the values divided by the number of values:\n\\(\\bar{X} = \\frac{\\text{sum of values}}{\\text{number of values}} = \\frac{x_1 + x_2 + ... + x_N}{N}=\\frac{1}{N}\\sum_{i=1}^{i=N} x_i\\)\nLet’s do this in R for our set of 10 values\n\n(0 + 0 + 0 + 0 + 1 + 1 + 0 + 1 + 0 + 1)/10\n\n[1] 0.4\n\n\nThe average outcome is .4. Note: when a variable contains only 0’s and 1’s its mean is the proportion of 1’s. 40% of people think the economy is doing well.\n\n2.3.1 Using functions in R (overview)\nA function is an action(s) that you request R to perform on an object or set of objects. For example, we will use the mean() function to ask R to take the mean or “average” of a vector.\n\nInside the function you place inputs or “arguments.”\n\n\nmean(Outcome)\n\n[1] 0.4\n\n\nR also has functions that take the sum sum() of a vector of values.\n\nsumofvalues <- sum(Outcome)\n\nAnd that count the total number of values or “length” length() of the vector.\n\nnumberofvalues <- length(Outcome)\n\nNote that the below is also equivalent to the mean\n\nsumofvalues / numberofvalues\n\n[1] 0.4\n\n\nReturning to our example, we found that 40% of people surveyed thought the economy was doing well. Surveying people about their opinions on how the country doing is a common way that social scientists use description. We could extend this exercise in many ways going forward, even with the same question.\n\nStart with a question: How is the economy doing?\nLet’s find a measure: Ask people if the economy is doing well.\nFind data points: Multiple people (we could stop there with the average!), or add more variables:\n\nAcross time: Survey people across multiple years\nAcross type of people: Survey different partisan groups\n\n\nThese types of survey trends are often used by news organizations and public opinion organizations like, Gallup.\n\nThis was just a first example of description in political science. There are many other ways to describe how the economy is doing and many other topics we might want to describe in politics."
  },
  {
    "objectID": "02-Description.html#loading-data-into-r",
    "href": "02-Description.html#loading-data-into-r",
    "title": "2  Description",
    "section": "2.4 Loading data into R",
    "text": "2.4 Loading data into R\nFor this section, our motivating example will be methods to measure voter turnout in the United States.\nDescribing voter turnout\n\nWhat is a typical level of voter turnout?\nHow has turnout changed over time?\nIs turnout higher in presidential years or in midterm years?\n\nHow can we measure turnout? Think about the validity, reliability, and cost of different approaches.\nExample: Dataset on Voter Turnout in the U.S. across multiple years\n\nIn this dataset, each row is an election year. Each column contains information about the population, potential voters, or voter turnout. These will help us compute the turnout rate in a given year. To work with this dataset, we need to load it into R.\n\n2.4.1 Working with datasets in R\nFor a video explainer of the code in this section, see below. The video only discusses the code. Use the notes and lecture discussion for additional context. (Via youtube, you can speed up the playback to 1.5 or 2x speed.)\n\n\n\n\n\n\n\n\n\nOften the variables we care about are stored inside of rectangular datasets\n\nThese have a number of rows nrow() and columns ncol()\nEach row is an “observation,” representing the information collected from an individual or entity\nEach column is a variable, representing a changing characteristic across multiple observations\n\nWhen we import a dataset into R, we have a few options.\nOption 1: Download dataset to your computer\n\nMove the dataset to your working directory\nIdentify the file type (e.g., csv, dta, RData, txt)\nPick the appropriate R function to match the type (e.g., read.csv(), read.dta(), load(), read.table())\nAssign the dataset to an object. This object will now be class() of data.frame\n\n\nturnout <- read.csv(\"turnout.csv\")\n\nOption 2: Read file from a url provided\n\nNeed an active internet connection for this to work\nURL generally must be public\nInclude the url inside the function used to read the data\n\n\nturnout <- read.csv(\"https://raw.githubusercontent.com/ktmccabe/teachingdata/main/turnout.csv\")\n\n\nclass(turnout)\n\n[1] \"data.frame\"\n\n\nYou can also open up a window to view the data:\n\nView(turnout)\n\n\n\n2.4.2 Measuring the Turnout in the US Elections\nRelevant questions with voter turnout\n\nWhat is a typical level of voter turnout?\nIs turnout higher in presidential years or in midterm years?\nIs turnout higher or lower based on voting-eligible (VEP) or voting-age (VAP) populations? We have a lot of people who are citizens 18 and older who are ineligible to vote. This makes the VEP denominator smaller than the VAP.\n\nVoter Turnout in the U.S.\n\nNumerator: total: Total votes cast (in thousands)\nDenominator:\n\nVAP: (voting-age population) from Census\nVEP (voting-eligible population) VEP = VAP + overseas voters - ineligible voters\n\nAdditional Variables and Descriptions\n\nyear: election year\nANES: ANES self-reported estimated turnout rate\nVEP: Voting Eligible Population (in thousands)\nVAP: Voting Age Population (in thousands)\ntotal: total ballots cast for highest office (in thousands)\nfelons: total ineligible felons (in thousands)\nnoncitizens: total non-citizens (in thousands)\noverseas: total eligible overseas voters (in thousands)\nosvoters: total ballots counted by overseas voters (in thousands)\n\n\n\n\n2.4.3 Getting to know your data\n\n## How many observations (the rows)?\nnrow(turnout)\n\n[1] 14\n\n## How many variables (the columns)?\nncol(turnout)\n\n[1] 9\n\n## What are the variable names?\nnames(turnout)\n\n[1] \"year\"     \"VEP\"      \"VAP\"      \"total\"    \"ANES\"     \"felons\"   \"noncit\"  \n[8] \"overseas\" \"osvoters\"\n\n## Show the first six rows\nhead(turnout)\n\n  year    VEP    VAP total ANES felons noncit overseas osvoters\n1 1980 159635 164445 86515   71    802   5756     1803       NA\n2 1982 160467 166028 67616   60    960   6641     1982       NA\n3 1984 167702 173995 92653   74   1165   7482     2361       NA\n4 1986 170396 177922 64991   53   1367   8362     2216       NA\n5 1988 173579 181955 91595   70   1594   9280     2257       NA\n6 1990 176629 186159 67859   47   1901  10239     2659       NA\n\n\nExtract a particular column (vector) from the data using the $.\n\nturnout$year\n\n [1] 1980 1982 1984 1986 1988 1990 1992 1994 1996 1998 2000 2002 2004 2008\n\n\nExtract the 10th year. Just like before! We use 10 to indicate the value of the year column in position (row 10) of the data.\n\nturnout$year[10]\n\n[1] 1998\n\n\nWe can take the mean() of a particular column, too. Let’s take it of the total number of voters.\n\nmean(turnout$total)\n\n[1] 89778.29\n\n\nAnd get the class() (Note: integer is just a type of numeric variable)\n\nclass(turnout$total)\n\n[1] \"integer\"\n\n\nWe can also use brackets in the full data frame, but because our data frame has BOTH rows and columns, we cannot just supply one position i. Instead, we have to tell R which row AND which column by using a comma between the positions.\n\nturnout[1,2] # value in row 1, column 2\n\n[1] 159635\n\n\nWe can use the column name instead\n\nturnout[1, \"VEP\"]\n\n[1] 159635\n\n\nIf we leave the second entry blank, it will return all columns for the specified row\n\nturnout[1,] # All variable values for row 1\n\n  year    VEP    VAP total ANES felons noncit overseas osvoters\n1 1980 159635 164445 86515   71    802   5756     1803       NA\n\n\nThe opposite is true if we leave the first entry blank.\n\nturnout[,2] # VEP for all rows\n\n [1] 159635 160467 167702 170396 173579 176629 179656 182623 186347 190420\n[11] 194331 198382 203483 213314"
  },
  {
    "objectID": "02-Description.html#comparing-vep-and-vap-turnout",
    "href": "02-Description.html#comparing-vep-and-vap-turnout",
    "title": "2  Description",
    "section": "2.5 Comparing VEP and VAP turnout",
    "text": "2.5 Comparing VEP and VAP turnout\n\n2.5.1 Creating new variables in R\nLet’s create a new variable that is VAP that adds overseas voters.\n\n# Use $ to add a new variable (i.e., column) to a dataframe\nturnout$VAPplusoverseas <- turnout$VAP + turnout$overseas\n\nUnder the hood, what this is doing is taking each value of turnout$VAP and adding it to its corresponding values of turnout$overseas.\nAnd, yes, this new variable shows up as a new column in turnout. Go ahead, View() it\n\nView(turnout)\n\nThis does not change the underlying turnout.csv file, only the turnout data.frame we are working with in the current R session.\n\nThis is an advantage of using an R script.\nYou don’t have to worry about overwriting/messing up the raw data.\nYou start from the original raw data when you load turnout.csv, and then everything else is done within R.\n\nThis is our new denominator. Now we can calculate turnout based on this denominator.\n\nturnout$newVAPturnout <- turnout$total / turnout$VAPplusoverseas\n\nJust like with adding two vectors, when we divide, each value in the first vector is divided by its corresponding value in the second vector.\n\nturnout$newVAPturnout\n\n [1] 0.5203972 0.4024522 0.5253748 0.3607845 0.4972260 0.3593884 0.5404097\n [8] 0.3803086 0.4753376 0.3483169 0.4934211 0.3582850 0.5454777 0.5567409\n\n\nLet’s calculate the VEP turnout rate and turn it into a percentage. This time, we do it in one step.\n\n(total votes / VEP) \\(\\times\\) 100:\n\n\nturnout$newVEPturnout <- (turnout$total / turnout$VEP) * 100\nturnout$newVEPturnout\n\n [1] 54.19551 42.13701 55.24860 38.14115 52.76848 38.41895 58.11384 41.12625\n [9] 51.65793 38.09316 54.22449 39.51064 60.10084 61.55433\n\n\nLet’s change it from a proportion to a percentage. How? Multiply each value of turnout$newVAP by 100\n\nturnout$newVAPturnout <- turnout$newVAPturnout * 100\n\nThis multiplies each number within the vector by 100.\n\nturnout$newVAPturnout\n\n [1] 52.03972 40.24522 52.53748 36.07845 49.72260 35.93884 54.04097 38.03086\n [9] 47.53376 34.83169 49.34211 35.82850 54.54777 55.67409\n\n\nWhat is typical turnout?\n\nmean(turnout$newVAPturnout)\n\n[1] 45.45658\n\nmean(turnout$newVEPturnout)\n\n[1] 48.94937\n\n\nWe find that turnout based on the voting age population is lower than turnout based on the voting eligible population. This is a pattern that political scientists have examined, going back several decades. For example, in a 2001 article McDonald and Popkin show that is it the ineligible population that grew from the 1970s onward and not the population of people who simply prefer not to vote. (See more here.)\n\n\n\nMcDonald and Popkin 2001"
  },
  {
    "objectID": "02-Description.html#comparing-presidential-vs.-midterm-turnout",
    "href": "02-Description.html#comparing-presidential-vs.-midterm-turnout",
    "title": "2  Description",
    "section": "2.6 Comparing Presidential vs. Midterm turnout",
    "text": "2.6 Comparing Presidential vs. Midterm turnout\nHow does turnout compare in presidential vs. midterm years? Sometimes using a single summary of turnout may obscure important underlying differences in the data. To detect these differences, we may want to summarize different parts of the data.\nOh dear. We need to extract specific years from the turnout data frame. Which rows contain the years we want?\n\nturnout$year\n\n [1] 1980 1982 1984 1986 1988 1990 1992 1994 1996 1998 2000 2002 2004 2008\n\n\nOk: rows 1,3,5,7,9,11,13,14 are the presidential. And rows 2,4,6,8,10,12 are midterms.\n\n## we can extract all of these at once by using c()\nturnout$year[c(1,3,5,7,9,11,13,14)] # presidential\n\n[1] 1980 1984 1988 1992 1996 2000 2004 2008\n\n\nLet’s take the mean VEP turnout for presidential years.\n\nmean(turnout$newVEPturnout[c(1,3,5,7,9,11,13,14)])\n\n[1] 55.983\n\n\nLet’s take the mean VEP turnout for midterm years.\n\nmean(turnout$newVEPturnout[c(2,4,6,8,10,12)])\n\n[1] 39.5712\n\n\nLet’s take the difference by storing each mean and then subtracting\n\nmean.VEP.pres <- mean(turnout$newVEPturnout[c(1,3,5,7,9,11,13,14)])\nmean.VEP.mid <- mean(turnout$newVEPturnout[c(2,4,6,8,10,12)])\nmean.VEP.pres -  mean.VEP.mid\n\n[1] 16.41181\n\n\nPresidential turnout, on average, is higher than midterm turnout.\n\n2.6.1 R shortcut for writing vectors\nSometimes we write numbers that are in a predictable sequence (e.g., 1,2,3,4,5). In R, we have functions that prevent us from having to type each number when this is the case.\n\nc(1,2,3,4,5) # is equivalent to:\n\n[1] 1 2 3 4 5\n\n1:5 # is equivalent to:\n\n[1] 1 2 3 4 5\n\nseq(from = 1, to = 5, by = 1)\n\n[1] 1 2 3 4 5\n\n\nWe can use the last one to our advantage to extract the midterm years, which go by 2\n\nmean(turnout$newVEPturnout[c(2,4,6,8,10,12)]) # is the same as\n\n[1] 39.5712\n\nmean(turnout$newVEPturnout[seq(2, 12, 2)])\n\n[1] 39.5712\n\n\nNot a big deal now, but imagine if you had to write 100 numbers or 1 MILLION NUMBERS!\nIn this section, we have described voter turnout using multiple measures and types of elections. There are several other questions that political scientists may be interested in when it comes to voter turnout.\nFor example, Texas and more than a dozen other states have passed new laws that change voting procedures in elections. What effect will these have on voter turnout? In the next section, we start to examine how to evaluate causal claims."
  },
  {
    "objectID": "03-CausalityI.html",
    "href": "03-CausalityI.html",
    "title": "3  Causation with Experiments",
    "section": "",
    "text": "Recall that we said, four primary goals of social science include:\nIn this section, we start to explore the goal of explanation–making causal claims."
  },
  {
    "objectID": "03-CausalityI.html#what-separates-causation-from-correlation",
    "href": "03-CausalityI.html#what-separates-causation-from-correlation",
    "title": "3  Causation with Experiments",
    "section": "3.1 What separates causation from correlation?",
    "text": "3.1 What separates causation from correlation?\nHere’s an example. In 2016, researchers at the NY Times noticed that areas in the country where the television show Duck Dynasty was popular also tended to support Donald Trump at higher rates.\n\nIf we put our social scientist hat on, we might want to distinguish whether this is a causal or, more likely, just a correlational relationship:\n\nCorrelation: Areas that watch Duck Dynasty are more likely to support Trump (degree to which two variables “move together”)\nCausality: Watching Duck Dynasty (vs. not watching) increases your support of Trump.\n\nCausal Question: Does the manipulation of one factor (the treatment), (holding everything else constant), cause a change in an outcome?\n\n3.1.1 Potential Outcomes Framework\nWhen studying causal relationships, we distinguish two concepts:\n\ntreatment: variable whose change may produce a change in the outcome\noutcome (\\(Y\\)): what may change as a result\n\nWe imagine two states of the world or “potential outcomes.”\n\n\\(Y(1)\\): the outcome if the treatment is administered\n\\(Y(0)\\): the outcome if the treatment is NOT administered (or maybe something else is)\n\nExample: How does voter turnout (\\(Y\\)) change as a result of varying whether someone receives a mail-in ballot (the treatment)?\n\n\\(Y(\\text{sent a mail-in ballot})\\): do you vote or not\n\\(Y(\\text{not sent a mail-in ballot})\\): do you vote or not\n\nWe compare your likelihood of turning out to vote in a world where you did receive a mail-in ballot vs. a counterfactual state of the world in which you did not receive a mail-in ballot, generally assuming that this is the only thing that is different between these two potential states of the world.\nIn many cases in social science, we might start by observing some connection in the real world (a factual observation). To make a causal claim, we then have to imagine what that counterfactual state of the world would be. Examples:\n\nCausal Question: Does the minimum wage increase the unemployment rate?\n\n(Hypothetical) Factual: An unemployment rate went up after the minimum wage increased\nImplied Counterfactual: Would the unemployment rate have gone up, had the minimum wage increase not occurred?\n\nCausal Question: Does race affect one’s job prospects?\n\n(Hypothetical) Factual: Jamal applied for a job but did not get it\nImplied Counterfactual: Would Jamal have gotten a job if he were white?\n\n\nWe use causal logic all of the time outside of social science.\nFor example, many viewers get angry after watching the movie Titanic because they believe Jack did not have to die. We can place their claims in our causal framework:\n\n\nOutcome: Jack Surviving the Titanic\nPotential Outcomes in two states of the world\n\nRose did not share the floating door, and Jack died.\nCounterfactual question: If Rose had shared the floating door, would Jack have lived?\n\n\nIn Bit by Bit, Matt Salganik notes that sometimes cause-and-effect questions are implicit. For example, in more general questions about maximization of some performance metric, we might want to compare several alternatives:\nThe question “What color should the donate button be on an NGO’s website?” is really lots of questions about the effect of different button colors on donations.\n\nFactual: A voter donates some amount with a black button\nCounterfactual: What would a voter donate if the button were blue?\nCounterfactual: What would a voter donate if the button were red?\n\nWhat other causal questions might social scientists or data scientists ask?\n\n\n3.1.2 Causal Effects\nWhen we are conducting a causal analysis, we will want to estimate a causal effect.\nA causal effect is the change in the outcome Y that is caused by a change in the treatment variable.\n\n\\(Y(1) - Y(0)\\) = causal effect or “treatment effect”\n\ne.g., Donation if contacted - Donation if not contacted\n\n\nWe often want to know the average treatment effect in some population, not just the causal effect for a single individual. Here, we might ask, on average, how much would our outcome change if our units were treated instead of untreated. To do so, we simply sum up all of the causal effects and divide them by the number of units in our population.\n\n\\(\\frac{1}{N} \\sum_{i=1}^N (Y_i (1)-Y_i (0))\\) = “average treatment effect” (ATE)\n\ne.g., Average donations if contacted - Average donations if not contacted\n\n\n\n\n3.1.3 Fundamental Problem of Causal Inference\nThe problem: Fundamental Problem of Causal Inference\nWhat makes the evaluation of causal claims difficult, is that in the real world, we suffer from the fundamental problem of causal inference:\n\nFor any individual, we only get to see (observe) the result from one state of the world\n\nThis makes that subtraction of potential outcomes impossible.\n\n\n(Unless we are in Groundhog Day or Russian Doll)"
  },
  {
    "objectID": "03-CausalityI.html#randomized-controlled-trials",
    "href": "03-CausalityI.html#randomized-controlled-trials",
    "title": "3  Causation with Experiments",
    "section": "3.2 Randomized Controlled Trials",
    "text": "3.2 Randomized Controlled Trials\nOne approach for addressing the fundamental problem of causal inference is to simulate two potential states of the world through random assignment: Randomized Controlled Trials / Experiments\nExperiments approximate factual vs. counterfactual comparison\n\nWe randomly assign one group to receive a “treatment” and another not to receive a treatment (the control)\nWhen treatment assignment is randomized, the only thing that distinguishes the treatment group from the control group, besides the treatment itself, is chance.\n\nThis allows us to compare the average outcomes between groups in order to estimate our causal effects (more on this below).\n\n3.2.1 Experiments: Why Randomize?\nRandomization is essential for being able to “identify” and isolate the causal effect of the treatment on the outcome. Without randomization, there may be several reasons why two groups differ beyond the treatment of interest.\nFor example, if we randomly assigned half of Rutgers seniors to watch the movie Groundhog Day and half to watch Parasite we would expect the groups to have about equal proportions of female students, average age, racial composition, majors, etc.\n\n(If we didn’t randomly assign, and just let people “select” into watching a particular movie, the groups could look very different.)\n\nBut because we randomized assignment, on average, we’d expect the two groups to be identical except for the treatment– in this case, which movie they watched.\n\nGreat news! This means any differences in the outcomes between the two groups can be attributed to the treatment. So if we wanted to see if Parasite leads people to have nightmares about people living in their basements, we could compare the average number of reported nightmares between the seniors that watched Parasite vs. Groundhog Day\n\n\n\n3.2.2 Experiments: How to Analyze\nDifference in Means: We compare each group’s average outcome by subtracting one from the other to estimate the average treatment effect (ATE) aka the average causal effect of the treatment.\n\n\\(\\widehat{ATE} = \\bar{Y}(treatment) - \\bar{Y}(control)\\)\n\nThis is an estimate of, on average, how much our outcome would change if units went from being untreated to treated.\n\nE.g., on average how much a person donates to a campaign if contacted by phone compared to if not contacted by phone.\n\n\n\n3.2.3 Ingredients of an Experiment\nFrom Bit by Bit\n\nFor every experiment, you should be able to\n\nState the causal question or relationship of interest\nDescribe how the experiment will be implemented (e.g., recruitment of subjects)\nIdentify and describe the randomization into treatment group(s) and control group and what happens in each group\nIdentify the outcome of interest, how it is measured\nEvaluate the relevant comparison\n\nWe will turn to an example in the next section."
  },
  {
    "objectID": "03-CausalityI.html#application-is-there-racial-discrimination-in-the-labor-market",
    "href": "03-CausalityI.html#application-is-there-racial-discrimination-in-the-labor-market",
    "title": "3  Causation with Experiments",
    "section": "3.3 Application: Is there racial discrimination in the labor market?",
    "text": "3.3 Application: Is there racial discrimination in the labor market?\nMarianne Bertrand and Sendhil Mullainathan. 2004. “Are Emily and Greg more employable than Lakisha and Jamal? A field experiment on labor market discrimination.”\n“We perform a field experiment to measure racial discrimination in the labor market. We respond with fictitious resumes to help-wanted ads in Boston and Chicago newspapers.”\n\nRecruitment: Construct resumes to send to ads\nRandomization: To manipulate perception of race, each resume is (randomly) assigned\nTreatment: either a very African American sounding name\nControl: or a very White sounding name\nOutcome: Does the resume receive a callback?\nComparison: Callback rates for African American (sounding) names vs. White (sounding) names (the difference in means between groups)\n\nFor a video explainer of the code in this section, see below. The video only discusses the code. Use the notes and lecture discussion for additional context. (Via youtube, you can speed up the playback to 1.5 or 2x speed.)\n\n\n\n\n\n\n\n\n\nLet’s load the data. Note: When we have variables that are text-based categories, we may want to tell R to treat these “strings” of text information as factor variables, a particular type of variable that represents data as a set of nominal (unordered) or ordinal (ordered) categories. We do this with the stringsAsFactors argument.\n\nresume <- read.csv(\"resume.csv\", stringsAsFactors = T)\n\n\nresume <- read.csv(\"https://raw.githubusercontent.com/ktmccabe/teachingdata/main/resume.csv\",\n                   stringsAsFactors = T)\n\nVariables and Description\n\nfirstname: first name of the fictitious job applicant\nsex: sex of applicant (female or male)\nrace: race of applicant (black or white)\ncall: whether a callback was made (1 = yes, 0 = no)\n\nThe data contain 4870 resumes and 4 variables.\n\nnrow(resume) # number of rows\n\n[1] 4870\n\nncol(resume) # number of columns\n\n[1] 4\n\ndim(resume) # number of rows and columns\n\n[1] 4870    4\n\n\nNote: These data look a little different from what we used last week. For example, the sex and race variables contain words, not numbers.\n\nhead(resume)\n\n  firstname    sex  race call\n1   Allison female white    0\n2   Kristen female white    0\n3   Lakisha female black    0\n4   Latonya female black    0\n5    Carrie female white    0\n6       Jay   male white    0\n\n\n\n3.3.1 Variable classes\nWe can check the class of each variable: Look, we have a new type, a “factor” variable.\n\nclass(resume$firstname)\n\n[1] \"factor\"\n\nclass(resume$sex)\n\n[1] \"factor\"\n\nclass(resume$race)\n\n[1] \"factor\"\n\nclass(resume$call)\n\n[1] \"integer\"\n\n\nWe have now encountered numeric, character, and factor vectors and/or variables in R. Note: This is simply how R understands them. Sometimes R can get it wrong. For example, if we write:\n\nsomenumbers <- c(\"1\", \"3\", \"4\")\nclass(somenumbers)\n\n[1] \"character\"\n\n\nBecause we put our numbers in quotation marks, R thinks the values in somenumbers are text. The number “3” might as well be the word “blue” for all R knows. Fortunately, we can easily switch between classes.\n\nsomenumbers <- as.numeric(somenumbers)\nclass(somenumbers)\n\n[1] \"numeric\"\n\n\nHere, we used as.numeric() to overwrite and change the character vector into a numeric vector.\nRules of Thumb\n\nUsually, we want character variables to store text (e.g., open-ended survey responses)\nWe want numeric variables to store numbers.\nUsually, we want factor variables to store categories.\n\nWithin R, factor variables assign a number to each category, which is given a label or level in the form of text.\nCategories might be ordinal or “ordered” (e.g., Very likely, Somewhat likely, Not likely) or\nUnordered (e.g., “male”, “female”)\nR won’t know if a factor variable is ordered or unordered. Alas, we have to be smarter than R.\nR might think you have a character variable when you want it to be a factor or the reverse.\n\nThat’s when as.factor() and as.character() are useful.\n\n\nAlways check class() to find out the variable type"
  },
  {
    "objectID": "03-CausalityI.html#making-tables",
    "href": "03-CausalityI.html#making-tables",
    "title": "3  Causation with Experiments",
    "section": "3.4 Making tables",
    "text": "3.4 Making tables\nA nice thing about numeric and factor variables is we can use the table command to see how many observations in our data fall into each category or numerical value.\n\n## Example: how many black vs. white sounding resumes\ntable(resume$race)\n\n\nblack white \n 2435  2435 \n\n\nAs mentioned, factor variables have levels:\n\nlevels(resume$race)\n\n[1] \"black\" \"white\"\n\n\n\n3.4.1 Crosstabulation\nWe can also use the table command to show a crosstabulation: a table that displays the frequency of observations across two variables.\n\n## Example: how many black vs. white sounding resumes by call backs\n## We can label the two dimensions of the table with the =\ntable(calledback = resume$call, race = resume$race)\n\n          race\ncalledback black white\n         0  2278  2200\n         1   157   235\n\n\nSometimes we will want to show the proportion instead of the frequency using prop.table\n\n## Example: proportion black vs. white sounding resumes by call backs\n## Convert to proportion\nprop.table(table(calledback = resume$call, race = resume$race), margin = 2) # 1 for row sum, 2 for col\n\n          race\ncalledback      black      white\n         0 0.93552361 0.90349076\n         1 0.06447639 0.09650924\n\n\nHow can we interpret this crosstabulation? It should let us see the causal effect– the callback rate for each group"
  },
  {
    "objectID": "03-CausalityI.html#conditional-means",
    "href": "03-CausalityI.html#conditional-means",
    "title": "3  Causation with Experiments",
    "section": "3.5 Conditional Means",
    "text": "3.5 Conditional Means\nAnother thing we can do with factor variables is to find how the average of one variable (e.g., our outcome- the callback rate) varies across different categories of our factor variable. For this, we use tapply().\n\n## take the mean of input1 by categories of input2\n## mean of call by race\ntapply(resume$call, INDEX=resume$race, mean)\n\n     black      white \n0.06447639 0.09650924"
  },
  {
    "objectID": "03-CausalityI.html#relational-operators-in-r",
    "href": "03-CausalityI.html#relational-operators-in-r",
    "title": "3  Causation with Experiments",
    "section": "3.6 Relational Operators in R",
    "text": "3.6 Relational Operators in R\nGoal: Compare callback rates for white sounding names to black sounding names, so we need to be able to filter by race.\nGood news: We have several relational operators in R that evaluate logical statements:\n\n==, <, >, <=, >=, !=\nWe have a statement and R evaluates it as TRUE or FALSE\n\n\n## for each observation, does the value of race equal \"black\"?\nresume$race == \"black\"\n\nBy putting this logical statement within [ ], we are asking R to take the mean() of the variable resume$call for the subset of observations for which this logical statement is TRUE.\n\nmean(resume$call[resume$race == \"black\"])\n\n[1] 0.06447639\n\n\nUltimately, each of these paths has led us to a place where we can estimate the average treatment effect by calculation the difference in means: the difference in callback rates for black and white applicants.\nWe said the ATE = \\(\\bar{Y}(treatment) - \\bar{Y}(control)\\)\n\nate <- mean(resume$call[resume$race == \"black\"]) - \n  mean(resume$call[resume$race == \"white\"])\nate\n\n[1] -0.03203285\n\n\nHow can we interpret this? Do white applicants have an advantage?"
  },
  {
    "objectID": "03-CausalityI.html#subsetting-data-in-r",
    "href": "03-CausalityI.html#subsetting-data-in-r",
    "title": "3  Causation with Experiments",
    "section": "3.7 Subsetting data in R",
    "text": "3.7 Subsetting data in R\nSubsetting Dataframes in R\nMaybe we are interested in differences in callbacks for females. One approach for looking at the treatment effect for female applicants, only, is to subset our data to include only female names.\n\nTo do this, we will assign a new data.frame object that keeps only those rows where sex == \"female\" and retains all columns\nBelow are two approaches for this subsetting, one that uses brackets and one that uses the subset function\n\n\n## option one\nfemales <- resume[resume$sex == \"female\", ]\n## option two using subset()- preferred\nfemales <- subset(resume, sex == \"female\")\n\nNow that we have subset the data, this simplifies estimating the ATE for female applicants only.\nWe said the ATE = \\(\\bar{Y}(treatment) - \\bar{Y}(control)\\)\n\nate.females <- mean(females$call[females$race == \"black\"]) -\n  mean(females$call[females$race == \"white\"])\nate.females\n\n[1] -0.03264689\n\n\n\n3.7.1 Getting Booooooooolean\nWe can make this slightly more complex by adding more criteria. Let’s say we wanted to know the callback rates for just female black (sounding) names.\n\nR allows use to use & (and) and | (or)\n\n\nfemaleblack <- subset(resume, sex == \"female\" & race == \"black\")\n\nWe could now find the callback rate for Black females using the tools from above:\n\nmean(femaleblack$call)\n\n[1] 0.06627784"
  },
  {
    "objectID": "03-CausalityI.html#creating-new-variables-using-conditional-statements",
    "href": "03-CausalityI.html#creating-new-variables-using-conditional-statements",
    "title": "3  Causation with Experiments",
    "section": "3.8 Creating New Variables using Conditional statements",
    "text": "3.8 Creating New Variables using Conditional statements\nWe can instead create a new variable in our main dataframe. Let’s make a variable that takes the value 1 if a name is female and black sounding and 0, otherwise\n\n# Initialize a new variable called femaleblackname\nresume$femaleblackname <- NA\n# Assign a 1 to our new variable where sex is female and race is black\nresume$femaleblackname[resume$sex == \"female\" & resume$race == \"black\"] <- 1\n# Assign a 0 if sex is not female OR if race is not black\nresume$femaleblackname[resume$sex != \"female\" | resume$race != \"black\"] <- 0\n\nWe can check our work\n\ntable(name = resume$firstname, femaleblack = resume$femaleblackname)\n\n          femaleblack\nname         0   1\n  Aisha      0 180\n  Allison  232   0\n  Anne     242   0\n  Brad      63   0\n  Brendan   65   0\n  Brett     59   0\n  Carrie   168   0\n  Darnell   42   0\n  Ebony      0 208\n  Emily    227   0\n  Geoffrey  59   0\n  Greg      51   0\n  Hakim     55   0\n  Jamal     61   0\n  Jay       67   0\n  Jermaine  52   0\n  Jill     203   0\n  Kareem    64   0\n  Keisha     0 183\n  Kenya      0 196\n  Kristen  213   0\n  Lakisha    0 200\n  Latonya    0 230\n  Latoya     0 226\n  Laurie   195   0\n  Leroy     64   0\n  Matthew   67   0\n  Meredith 187   0\n  Neil      76   0\n  Rasheed   67   0\n  Sarah    193   0\n  Tamika     0 256\n  Tanisha    0 207\n  Todd      68   0\n  Tremayne  69   0\n  Tyrone    75   0\n\n\nLet’s say we wanted to know the callback rates for just female black (sounding) names.\n\nmean(femaleblack$call)\n\n[1] 0.06627784\n\nmean(resume$call[resume$femaleblackname == 1])\n\n[1] 0.06627784\n\n\nBINGO: two ways to do the same thing.\n\n3.8.1 ifelse statements\nRemember how we created the variable femaleblack, well there is another way to do that in R using what are called conditional statements with ifelse().\n\nCan be read: If this relational statement is TRUE, I assign you A, otherwise I assign you B\n\n\nresume$femaleblackname <- ifelse(resume$sex == \"female\" &\n                                   resume$race == \"black\", 1, 0)\n\nCan be read: If sex is female and race is black, give the observation in the new variable a 1, otherwise give it a 0.\nLike most things, we can also get more complicated here. Let’s say we wanted to create a variable that indicated both race and sex.\n\nCan be read: If this relational statement is TRUE, I assign you A,\nOtherwise if this second relational statement is TRUE, I assign you B,\nOtherwise if this third relational statement is TRUE, I assign you C,\nOtherwise I assign you D\n\n\nresume$racesex <- ifelse(resume$sex == \"female\" &\n                                   resume$race == \"black\", \"FemaleBlack\", \n                         ifelse(resume$sex == \"female\" &\n                                   resume$race == \"white\", \"FemaleWhite\",\n                                ifelse(resume$sex == \"male\" &\n                                   resume$race == \"white\", \"MaleWhite\", \"MaleBlack\")))\n\nNote: what you assign can be numeric or text."
  },
  {
    "objectID": "03-CausalityI.html#types-of-experiments",
    "href": "03-CausalityI.html#types-of-experiments",
    "title": "3  Causation with Experiments",
    "section": "3.9 Types of Experiments",
    "text": "3.9 Types of Experiments\nExperiments can vary:\n\nSetting: Lab, Survey, Field\nMode: Analog vs. Digital\nAnd in Validity\n\nInternal: were the processes conducted in a correct, reliable way?\nExternal: can we generalize from the experiment to the real world, or would the results change?\nContext: Would people act the same way outside of the experiment?\nRecruitment: Are the people in our experiment representative of the people we care about?\nConstruct\n\nTreatment: Is the experimental treatment similar to what people see in the real world?\nOutcome: Is the outcome something we care about in the real world? Are we measuring it in a realistic, accurate way?\n\n\n\nReview Bit by Bit chapter 4 for more examples of social science experiments."
  }
]